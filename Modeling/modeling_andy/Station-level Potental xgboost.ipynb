{"cells":[{"cell_type":"markdown","source":["## Using best hyperparameters for XGBoost model:"],"metadata":{"id":"tRuao3NW3c_T"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"CoeOlVC5AtFB","colab":{"base_uri":"https://localhost:8080/","height":440},"outputId":"00da5554-da36-417e-c20f-f1270d2f3f83","executionInfo":{"status":"error","timestamp":1741744673879,"user_tz":300,"elapsed":348515,"user":{"displayName":"Zimeng Huang","userId":"11912824630688390396"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-1-3297286621c3>:16: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n","  train = pd.read_csv(\"/content/drive/Shared drives/Time Series/divvy_data/prod/station/divvy_station_train.csv\")\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3297286621c3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mbest_xgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mbest_xgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Ensure test features match train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1171\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             _check_call(\n\u001b[0;32m-> 2101\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2102\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m                 )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# XGBoost\n","from xgboost import XGBRegressor\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","\n","# âœ… Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Load training and test data\n","train = pd.read_csv(\"/content/drive/Shared drives/Time Series/divvy_data/prod/station/divvy_station_train.csv\")\n","test = pd.read_csv(\"/content/drive/Shared drives/Time Series/divvy_data/prod/station/divvy_station_test.csv\")\n","\n","# Ensure dates are in datetime format\n","train['ds'] = pd.to_datetime(train['date'])\n","test['ds'] = pd.to_datetime(test['date'])\n","train.drop(columns=['date'], inplace=True)\n","test.drop(columns=['date'], inplace=True)\n","\n","# Create lag features on train ONLY\n","for lag in [1, 2, 7, 30, 60, 90, 365]:\n","    train[f'y_lag{lag}'] = train.groupby('start_station_name')['total_rides'].shift(lag)\n","\n","# Feature engineering for XGBoost\n","for df in [train, test]:\n","    df['day'] = df['ds'].dt.day\n","    df['month'] = df['ds'].dt.month\n","    df['year'] = df['ds'].dt.year\n","    df['weekday'] = df['ds'].dt.weekday\n","    df['week_of_year'] = df['ds'].dt.isocalendar().week\n","    df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)\n","    df['rain_intensity'] = pd.cut(df['rain_sum_mm'], bins=[-1, 0, 5, 20, np.inf], labels=[0, 1, 2, 3])\n","    df['snow_flag'] = (df['snowfall_sum_cm'] > 0).astype(int)\n","    df['rolling_avg_7'] = df.groupby('start_station_name')['total_rides'].transform(lambda x: x.rolling(window=7, min_periods=1).mean())\n","    df['rolling_avg_30'] = df.groupby('start_station_name')['total_rides'].transform(lambda x: x.rolling(window=30, min_periods=1).mean())\n","    df['ride_growth'] = df.groupby('start_station_name')['total_rides'].transform(lambda x: x.pct_change(periods=7).fillna(0))\n","    df['rain_intensity'] = df['rain_intensity'].astype(float)\n","    df['weekend_rain'] = df['is_weekend'] * df['rain_intensity']\n","    df['cold_no_snow'] = (df['temp_min_c'] < 5) & (df['snow_flag'] == 0)\n","\n","# Drop the datetime column, start_station_id\n","train.drop(columns=['ds', 'start_station_id'], inplace=True)\n","test.drop(columns=['ds', 'start_station_id'], inplace=True)\n","\n","# Ensure only common stations exist in test before encoding\n","test = test[test['start_station_name'].isin(train['start_station_name'].unique())]\n","\n","# One-hot encoding\n","train = pd.get_dummies(train, columns=['start_station_name'], drop_first=True)\n","test = pd.get_dummies(test, columns=['start_station_name'], drop_first=True)\n","\n","# Align test columns with train columns\n","test = test.reindex(columns=train.columns, fill_value=0)\n","\n","# Prepare data for XGBoost\n","X_train = train.drop(columns=['total_rides'])\n","y_train = train['total_rides']\n","X_test = test.drop(columns=['total_rides'])\n","y_test = test['total_rides']\n","\n","best_params = {\n","    'colsample_bytree': 0.8,\n","    'learning_rate': 0.1,\n","    'max_depth': 10,\n","    'n_estimators': 1000,\n","    'subsample': 0.8\n","}\n","\n","best_xgb_model = XGBRegressor(**best_params, random_state=42)\n","best_xgb_model.fit(X_train, y_train)\n","\n","# Ensure test features match train\n","X_test = X_test[X_train.columns]\n","\n","# Make predictions\n","y_pred = best_xgb_model.predict(X_test)\n","\n","# Evaluate the model\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","print(f\"RMSE: {rmse}\")\n","\n","# Forecast horizon (number of days to forecast into the future)\n","forecast_horizon = 365\n","\n","# Create a dataframe for future dates\n","future_dates = pd.date_range(start=test['ds'].max(), periods=forecast_horizon, freq='D')\n","future_df = pd.DataFrame({'ds': future_dates})\n","\n","# Calculate potential for each station (same as before)\n","potential = {}\n","stations = train.columns[train.columns.str.startswith('start_station_name_')]\n","for station in stations:\n","    train_mean = train[train[station] == 1]['total_rides'].mean()\n","    test_mean = test[test[station] == 1]['total_rides'].mean()\n","    potential[station] = test_mean - train_mean\n","\n","# Sort stations by potential and select top 3 (same as before)\n","top_3_stations = sorted(potential.items(), key=lambda x: x[1], reverse=True)[:3]\n","\n","# Initialize a list to store predictions\n","future_predictions = []\n","\n","# Recursive forecasting loop\n","for i in range(forecast_horizon):\n","    # Create lag features for the current prediction step\n","    current_date = future_dates[i]\n","    for lag in [1, 2, 7, 30, 60, 90, 365]:\n","        if i >= lag:\n","            future_df.loc[i, f'y_lag{lag}'] = future_predictions[i - lag]\n","        else:\n","            # Use the last lag values from the TRAINING set for initial lags\n","            future_df.loc[i, f'y_lag{lag}'] = train['total_rides'].iloc[-lag]\n","\n","    # Feature engineering for the current date\n","    future_df.loc[i, 'day'] = current_date.day\n","    future_df.loc[i, 'month'] = current_date.month\n","    future_df.loc[i, 'year'] = current_date.year\n","    future_df.loc[i, 'weekday'] = current_date.weekday\n","    future_df.loc[i, 'week_of_year'] = current_date.isocalendar().week\n","    future_df.loc[i, 'is_weekend'] = int(current_date.weekday in [5, 6])\n","    # Add other feature engineering steps if needed (e.g., weather data)\n","\n","    # One-hot encoding for start_station_name (assuming the same encoding as train/test)\n","    # Adjust this part based on your specific one-hot encoding scheme\n","    for station_col in X_train.columns[X_train.columns.str.startswith('start_station_name_')]:\n","        future_df.loc[i, station_col] = 0  # Initialize to 0\n","        # Set to 1 if the station matches the current station (you'll need logic here)\n","\n","        # Check if the current station is in the top 3\n","        station_name = station_col.replace('start_station_name_', '')\n","        if any(station_name in s for s, _ in top_3_stations):\n","            future_df.loc[i, station_col] = 1  # Set to 1 if in top 3\n","\n","    # Ensure future_df has the same columns as X_train\n","    future_df = future_df.reindex(columns=X_train.columns, fill_value=0)\n","\n","    # Make prediction for the current date\n","    current_prediction = best_xgb_model.predict(future_df.iloc[[i]])[0]\n","    future_predictions.append(current_prediction)\n","\n","# Add the predictions to the future_df\n","future_df['predicted_rides'] = future_predictions\n","\n","# Print or visualize the predictions\n","print(future_df[['ds', 'predicted_rides']])\n","\n","# Basic visualization using matplotlib\n","plt.figure(figsize=(12, 6))\n","plt.plot(test['ds'], y_test, label='Actual (Test Set - All Stations)', color='gray', alpha=0.5)  # Plot overall actual rides\n","\n","for station, _ in top_3_stations:\n","    station_name = station.replace('start_station_name_', '')  # Get station name\n","\n","    # Filter predictions for the current station\n","    station_predictions = future_df[future_df[station] == 1]['predicted_rides']\n","\n","    # Plot predictions for the current station\n","    plt.plot(future_df['ds'], station_predictions, label=f'Predicted ({station_name})')\n","\n","plt.xlabel('Date')\n","plt.ylabel('Total Rides')\n","plt.title('Bike Rides Forecast (Top 3 Stations)')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"vVvFoXW0AEjo","executionInfo":{"status":"aborted","timestamp":1741744673884,"user_tz":300,"elapsed":28,"user":{"displayName":"Zimeng Huang","userId":"11912824630688390396"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}